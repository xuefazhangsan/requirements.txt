import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import io

# ==================== 1. æ ¸å¿ƒé…ç½® ====================
st.set_page_config(page_title="é…·ç‹—æ¦œå•åŠ©æ‰‹(æ‰‹æœºç‰ˆ)", page_icon="ğŸµ")

# è®¾ç½®è¯·æ±‚å¤´ï¼Œä¼ªè£…æˆæµè§ˆå™¨
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36",
    "Referer": "https://www.kugou.com/"
}

# ==================== 2. åŠŸèƒ½æ¨¡å— ====================

def crawl_kugou_data():
    """åŠŸèƒ½ä¸€ï¼šæŠ“å–é…·ç‹—é£™å‡æ¦œ"""
    data_list = []
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    try:
        for page in range(1, 6): # çˆ¬å–å‰5é¡µï¼Œå…±100å¤šé¦–
            url = f"https://www.kugou.com/yy/rank/home/{page}-6666.html?from=rank"
            status_text.text(f"æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µ...")
            
            response = requests.get(url, headers=HEADERS, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            song_list = soup.select(".pc_temp_songlist > ul > li")
            
            if not song_list:
                break
                
            for item in song_list:
                try:
                    # æå–æ’å
                    rank_str = item.select_one(".pc_temp_num").get_text(strip=True)
                    rank = int(rank_str)
                    
                    # æå–æ­Œåå’Œæ­Œæ‰‹ (æ ¼å¼é€šå¸¸ä¸º: æ­Œæ‰‹ - æ­Œå)
                    full_title = item.get("title", "").strip()
                    if "-" in full_title:
                        parts = full_title.split("-", 1)
                        singer = parts[0].strip()
                        song_name = parts[1].strip()
                    else:
                        singer = "æœªçŸ¥æ­Œæ‰‹"
                        song_name = full_title
                    
                    data_list.append({
                        "æ¦œå•åæ¬¡": rank,
                        "çº¯æ­Œæ›²åç§°": song_name,
                        "æ­Œæ‰‹": singer,
                        "çˆ¬å–æ—¶é—´": datetime.now().strftime("%mæœˆ%dæ—¥%Hæ—¶%Måˆ†")
                    })
                except Exception:
                    continue
            
            progress_bar.progress(page / 5)
            time.sleep(0.5) # ç¤¼è²Œçˆ¬è™«
            
        status_text.text("âœ… æŠ“å–å®Œæˆï¼")
        progress_bar.empty()
        
        # æˆªå–å‰100å
        df = pd.DataFrame(data_list)
        df = df.sort_values("æ¦œå•åæ¬¡").head(100)
        return df
        
    except Exception as e:
        st.error(f"æŠ“å–å¤±è´¥: {str(e)}")
        return None

def merge_history(history_df, new_df):
    """åŠŸèƒ½äºŒï¼šæ±‡æ€»æ•°æ®"""
    if history_df is None:
        return new_df
    
    # åˆå¹¶æ—§æ•°æ®å’Œæ–°æ•°æ®
    merged = pd.concat([history_df, new_df], ignore_index=True)
    
    # å»é‡é€»è¾‘ï¼šåŒä¸€æ—¶é—´ã€åŒä¸€é¦–æ­Œåªä¿ç•™ä¸€æ¡
    # ä½ çš„åŸä»£ç é€»è¾‘æ˜¯â€œæ— å»é‡â€ï¼Œä½†ä¸ºäº†é¢„æµ‹å‡†ç¡®ï¼Œå»ºè®®è¿˜æ˜¯è¦åšç®€å•çš„é‡å¤æ£€æŸ¥
    # è¿™é‡Œä¿ç•™åŸé€»è¾‘ï¼šç®€å•è¿½åŠ ï¼Œä½†ä¸ºäº†ç»˜å›¾ä¸å‡ºé”™ï¼Œæˆ‘ä»¬è½¬æ¢ä¸€ä¸‹æ—¶é—´æ ¼å¼
    return merged

def predict_trends(df):
    """åŠŸèƒ½ä¸‰ï¼šé¢„æµ‹ä¸è¶‹åŠ¿åˆ†æ"""
    # 1. æ•°æ®æ¸…æ´—ï¼šæå–æ—¥æœŸ
    # å‡è®¾â€œçˆ¬å–æ—¶é—´â€æ ¼å¼ä¸º "11æœˆ25æ—¥13æ—¶20åˆ†"
    # æˆ‘ä»¬éœ€è¦å°†å…¶æ ‡å‡†åŒ–ä»¥ä¾¿æ’åº
    
    # åªæœ‰ä¸€å¤©æ•°æ®æ— æ³•é¢„æµ‹
    if df['çˆ¬å–æ—¶é—´'].nunique() < 2:
        st.warning("âš ï¸ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆè¶‹åŠ¿é¢„æµ‹ã€‚è¯·è‡³å°‘ä¸Šä¼ åŒ…å«å†å²æ•°æ®çš„æ–‡ä»¶ï¼Œæˆ–åœ¨ä¸åŒæ—¶é—´æŠ“å–ä¸¤æ¬¡ã€‚")
        return None, None

    # åˆ›å»ºé€è§†è¡¨ï¼šè¡Œ=æ­Œå+æ­Œæ‰‹ï¼Œåˆ—=çˆ¬å–æ—¶é—´ï¼Œå€¼=æ¦œå•åæ¬¡
    pivot = df.pivot_table(index=['çº¯æ­Œæ›²åç§°', 'æ­Œæ‰‹'], columns='çˆ¬å–æ—¶é—´', values='æ¦œå•åæ¬¡', aggfunc='min')
    
    # è·å–æœ€è¿‘çš„å‡ ä¸ªæ—¶é—´ç‚¹
    time_cols = sorted(pivot.columns, key=lambda x: x) # ç®€å•å­—ç¬¦ä¸²æ’åºï¼Œæœ€å¥½æ˜¯è½¬datetime
    recent_times = time_cols[-5:] # å–æœ€è¿‘5æ¬¡
    
    recent_data = pivot[recent_times]
    
    # è®¡ç®—å¾—åˆ† (ç®€å•åŠ¨é‡ç­–ç•¥ï¼šæ’åè¶Šé å‰å¾—åˆ†è¶Šé«˜ï¼Œåæ¬¡ä¸Šå‡å¾—åˆ†è¶Šé«˜)
    scores = []
    for idx, row in recent_data.iterrows():
        # è¿™é‡Œç®€åŒ–ä½ çš„æ‰“åˆ†é€»è¾‘
        current_rank = row.iloc[-1]
        if pd.isna(current_rank): # ä»Šå¤©ä¸åœ¨æ¦œ
            scores.append(0)
            continue
            
        base_score = 101 - current_rank # åŸºç¡€åˆ†
        
        # è¶‹åŠ¿åˆ†
        trend_score = 0
        if len(row) >= 2 and pd.notna(row.iloc[-2]):
            prev_rank = row.iloc[-2]
            diff = prev_rank - current_rank # æ­£æ•°ä»£è¡¨ä¸Šå‡
            trend_score = diff * 2
            
        final_score = base_score + trend_score
        scores.append(final_score)
    
    result_df = pd.DataFrame({
        "çº¯æ­Œæ›²åç§°": [x[0] for x in recent_data.index],
        "æ­Œæ‰‹": [x[1] for x in recent_data.index],
        "é¢„æµ‹æŒ‡æ•°": scores,
        "ä»Šæ—¥æ’å": recent_data.iloc[:, -1].values
    })
    
    # ç­›é€‰å‰20åæ½œåŠ›è‚¡
    top_20 = result_df.sort_values("é¢„æµ‹æŒ‡æ•°", ascending=False).head(20)
    
    # æå–ç”¨äºç”»å›¾çš„æ•°æ®
    top_songs = list(zip(top_20['çº¯æ­Œæ›²åç§°'], top_20['æ­Œæ‰‹']))
    chart_data = recent_data.loc[top_songs].T # è½¬ç½®ï¼Œè¡Œæ˜¯æ—¶é—´ï¼Œåˆ—æ˜¯æ­Œæ›²
    
    return top_20, chart_data

# ==================== 3. ä¸»ç•Œé¢é€»è¾‘ ====================

st.title("ğŸ“± é…·ç‹—æ¦œå•åŠ©æ‰‹ (Mobile)")

st.info("ğŸ’¡ ä½¿ç”¨æµç¨‹ï¼šæŠ“å–ä»Šæ—¥æ•°æ® -> (å¯é€‰)ä¸Šä¼ å†å²æ•°æ® -> è‡ªåŠ¨åˆå¹¶ -> æŸ¥çœ‹é¢„æµ‹")

# --- æ­¥éª¤ 1: æŠ“å– ---
st.header("1. è·å–ä»Šæ—¥æ•°æ®")
if st.button("ğŸš€ å¼€å§‹æŠ“å–æœ€æ–°æ¦œå•"):
    with st.spinner("æ­£åœ¨è¿æ¥é…·ç‹—æœåŠ¡å™¨..."):
        new_data = crawl_kugou_data()
        if new_data is not None:
            st.success(f"æˆåŠŸæŠ“å– {len(new_data)} æ¡æ•°æ®ï¼")
            st.session_state['new_data'] = new_data
            st.dataframe(new_data.head(5))

# --- æ­¥éª¤ 2: å†å²æ•°æ®ç®¡ç† ---
st.header("2. å†å²æ•°æ®åº“")
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ ä¹‹å‰çš„ã€æ±‡æ€»è¡¨.xlsxã€‘(å¦‚æœæœ‰)", type=['xlsx'])

history_df = None
if uploaded_file:
    try:
        history_df = pd.read_excel(uploaded_file)
        st.write(f"å·²åŠ è½½å†å²æ•°æ®: {len(history_df)} æ¡")
    except:
        st.error("æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¯·ç¡®ä¿æ˜¯æ ‡å‡†çš„Excelæ–‡ä»¶")

# --- æ­¥éª¤ 3: æ±‡æ€»ä¸é¢„æµ‹ ---
st.header("3. åˆ†æä¸å¯¼å‡º")

if 'new_data' in st.session_state:
    # è‡ªåŠ¨åˆå¹¶
    current_new = st.session_state['new_data']
    final_df = merge_history(history_df, current_new)
    
    # --- é¢„æµ‹ ---
    st.subheader("ğŸ“Š æ½œåŠ›é£™å‡é¢„æµ‹")
    top_20, chart_data = predict_trends(final_df)
    
    if top_20 is not None:
        # æ˜¾ç¤ºè¡¨æ ¼
        st.write("ğŸ”¥ é¢„æµ‹æ’åå‰ 20ï¼š")
        st.dataframe(top_20[['çº¯æ­Œæ›²åç§°', 'æ­Œæ‰‹', 'ä»Šæ—¥æ’å', 'é¢„æµ‹æŒ‡æ•°']])
        
        # æ˜¾ç¤ºäº¤äº’å¼æŠ˜çº¿å›¾ (æ›¿ä»£åŸæ¥çš„é™æ€å›¾ï¼Œæ‰‹æœºä½“éªŒæ›´å¥½)
        st.write("ğŸ“ˆ æ’åèµ°åŠ¿å›¾ (è¶Šä½è¶Šå¥½)ï¼š")
        # è¿™é‡Œçš„å›¾è¡¨æ˜¯äº¤äº’å¼çš„ï¼Œæ‰‹æœºä¸Šå¯ä»¥ç‚¹å‡»æŸ¥çœ‹æ•°å€¼
        st.line_chart(chart_data)
    
    # --- å¯¼å‡ºåŠŸèƒ½ (æ‰‹æœºä¿å­˜) ---
    st.subheader("ğŸ’¾ ä¿å­˜ç»“æœ")
    
    # 1. å¯¼å‡ºæ±‡æ€»è¡¨
    buffer_summary = io.BytesIO()
    final_df.to_excel(buffer_summary, index=False)
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æœ€æ–°æ±‡æ€»è¡¨ (å«å†å²)",
        data=buffer_summary,
        file_name=f"é…·ç‹—æ¦œå•æ±‡æ€»_{datetime.now().strftime('%Y%m%d')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
else:
    st.write("ğŸ‘† è¯·å…ˆç‚¹å‡»ã€å¼€å§‹æŠ“å–ã€‘æŒ‰é’®")
